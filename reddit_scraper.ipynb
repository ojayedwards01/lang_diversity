{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXIawlO1nR1O"
      },
      "source": [
        "https://www.reddit.com/prefs/apps?solution=7b9d461eefb331747b9d461eefb33174&js_challenge=1&token=54dba411ecc9fd270bca6277dc2a43613d98a311bc0fd0a2e34ee9db5ef1f832"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ3z9KVCf5OR",
        "outputId": "920bdb87-e450-4803-df79-2b73a8891aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install requests bs4 praw -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tw3DaYlp-hb",
        "outputId": "7650f2c8-ca0c-4794-e7ed-897f1cffc906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraped 165 posts\n",
            "                                               title  \\\n",
            "0  Amharic is easy, concise and Flexible, not unp...   \n",
            "1                    I think this is Amharic, right?   \n",
            "2  Hello, I'm French, I understand written Englis...   \n",
            "3                 Can I get you something translated   \n",
            "4                                   Translation help   \n",
            "\n",
            "                                             content                 date  \n",
            "0  # አማርኛ እንዳረጓት ትሆናለች! (ወደ ብልግና እንዳትወስዱት)\\n\\nIn ...  2025-08-10 05:54:38  \n",
            "1  Hello mates,\\nI have a screenshot of a book's ...  2025-08-09 08:11:18  \n",
            "2                                                     2025-08-08 09:31:59  \n",
            "3  Why is this language so hard?\\n\\nI was told to...  2025-08-05 03:13:06  \n",
            "4  Hello! Can someone please assist me with trans...  2025-07-28 18:44:44  \n"
          ]
        }
      ],
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from datetime import timezone\n",
        "\n",
        "def scrape_subreddit_year(client_id, client_secret, user_agent, subreddit_name, days_back=365):\n",
        "    \"\"\"\n",
        "    Scrape posts from a subreddit within the past year\n",
        "    Returns only title, content, and date\n",
        "    \"\"\"\n",
        "    # Connect to Reddit\n",
        "    reddit = praw.Reddit(\n",
        "        client_id=client_id,\n",
        "        client_secret=client_secret,\n",
        "        user_agent=user_agent,\n",
        "        check_for_async=False\n",
        "    )\n",
        "\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "\n",
        "    # Calculate cutoff date (1 year ago)\n",
        "    cutoff_date = datetime.datetime.now(timezone.utc) - datetime.timedelta(days=days_back)\n",
        "    cutoff_timestamp = cutoff_date.timestamp()\n",
        "\n",
        "    posts_data = []\n",
        "\n",
        "    # Get posts sorted by new (most recent first)\n",
        "    for post in subreddit.new(limit=None):\n",
        "        # Stop if post is older than our cutoff\n",
        "        if post.created_utc < cutoff_timestamp:\n",
        "            break\n",
        "\n",
        "        posts_data.append({\n",
        "            'title': post.title,\n",
        "            'content': post.selftext,  # Post content/text\n",
        "            'date': datetime.datetime.fromtimestamp(post.created_utc, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(posts_data)\n",
        "    return df\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your Reddit API credentials\n",
        "    CLIENT_ID = \"IDkMsz3zveaxGNnXUuurGA\"\n",
        "    CLIENT_SECRET = \"TVvMagRJjJtGuQtCaOeFmbxjheNNVQ\"\n",
        "    USER_AGENT = \"digihum\"\n",
        "\n",
        "    # Scrape posts\n",
        "    df = scrape_subreddit_year(CLIENT_ID, CLIENT_SECRET, USER_AGENT, \"amharic\")\n",
        "\n",
        "    print(f\"Scraped {len(df)} posts\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(\"amharic_reddit_posts.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW_jOPwJsxBG"
      },
      "source": [
        "# Language Detection with AfroLID"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
